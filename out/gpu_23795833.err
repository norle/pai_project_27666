Loaded module: cuda/11.6
/zhome/85/8/203063/pai_course/pai/lib64/python3.9/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)
  warnings.warn(
Traceback (most recent call last):
  File "/zhome/85/8/203063/pai_course/project/transf_vae_v6.py", line 260, in <module>
    output, mu, logvar = model(src, trg_input, src_mask=src_mask, trg_mask=trg_mask)
  File "/zhome/85/8/203063/pai_course/pai/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/85/8/203063/pai_course/pai/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/85/8/203063/pai_course/project/transf_vae_v6.py", line 205, in forward
    output = self.decode(z, trg, trg_mask, trg_padding_mask, memory_key_padding_mask)
  File "/zhome/85/8/203063/pai_course/project/transf_vae_v6.py", line 199, in decode
    output = self.decoder(trg, memory, trg_mask, None, trg_padding_mask, memory_key_padding_mask)
  File "/zhome/85/8/203063/pai_course/pai/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/85/8/203063/pai_course/pai/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/85/8/203063/pai_course/pai/lib64/python3.9/site-packages/torch/nn/modules/transformer.py", line 602, in forward
    output = mod(
  File "/zhome/85/8/203063/pai_course/pai/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/85/8/203063/pai_course/pai/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/85/8/203063/pai_course/pai/lib64/python3.9/site-packages/torch/nn/modules/transformer.py", line 1091, in forward
    + self._mha_block(
  File "/zhome/85/8/203063/pai_course/pai/lib64/python3.9/site-packages/torch/nn/modules/transformer.py", line 1127, in _mha_block
    x = self.multihead_attn(
  File "/zhome/85/8/203063/pai_course/pai/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
  File "/zhome/85/8/203063/pai_course/pai/lib64/python3.9/site-packages/torch/nn/modules/module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
  File "/zhome/85/8/203063/pai_course/pai/lib64/python3.9/site-packages/torch/nn/modules/activation.py", line 1368, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/zhome/85/8/203063/pai_course/pai/lib64/python3.9/site-packages/torch/nn/functional.py", line 6278, in multi_head_attention_forward
    attn_output = scaled_dot_product_attention(
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 488.00 MiB. GPU 0 has a total capacity of 19.50 GiB of which 264.94 MiB is free. Including non-PyTorch memory, this process has 19.21 GiB memory in use. Of the allocated memory 18.96 GiB is allocated by PyTorch, and 101.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)
